<!DOCTYPE html><html lang="en" data-astro-cid-bvzihdzo> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.1.1"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://gowind.github.io/blog/is_simd_always_faster/"><!-- Primary Meta Tags --><title>IS SIMD always faster ?</title><meta name="title" content="IS SIMD always faster ?"><meta name="description" content="Can I make my code run faster by just using SIMD instructions ?"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://gowind.github.io/blog/is_simd_always_faster/"><meta property="og:title" content="IS SIMD always faster ?"><meta property="og:description" content="Can I make my code run faster by just using SIMD instructions ?"><meta property="og:image" content="https://gowind.github.io/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://gowind.github.io/blog/is_simd_always_faster/"><meta property="twitter:title" content="IS SIMD always faster ?"><meta property="twitter:description" content="Can I make my code run faster by just using SIMD instructions ?"><meta property="twitter:image" content="https://gowind.github.io/blog-placeholder-1.jpg"><!-- Cloudflare Web Analytics --><script defer src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;4de85a62d838459fafd8a042c2f1c7c2&quot;}"></script><!-- End Cloudflare Web Analytics --><style>:root{--accent: #2337ff;--accent-dark: #000d8a;--black: 15, 18, 25;--gray: 96, 115, 159;--gray-light: 229, 233, 240;--gray-dark: 34, 41, 57;--gray-gradient: rgba(var(--gray-light), 50%), #fff;--box-shadow: 0 2px 6px rgba(var(--gray), 25%), 0 8px 24px rgba(var(--gray), 33%), 0 16px 32px rgba(var(--gray), 33%)}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-regular.woff) format("woff");font-weight:400;font-style:normal;font-display:swap}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-bold.woff) format("woff");font-weight:700;font-style:normal;font-display:swap}body{font-family:Atkinson,sans-serif;margin:0;padding:0;text-align:left;background:linear-gradient(var(--gray-gradient)) no-repeat;background-size:100% 600px;word-wrap:break-word;overflow-wrap:break-word;color:rgb(var(--gray-dark));font-size:20px;line-height:1.7}main{width:720px;max-width:calc(100% - 2em);margin:auto;padding:3em 1em}h1,h2,h3,h4,h5,h6{margin:0 0 .5rem;color:rgb(var(--black));line-height:1.2}h1{font-size:3.052em}h2{font-size:2.441em}h3{font-size:1.953em}h4{font-size:1.563em}h5{font-size:1.25em}strong,b{font-weight:700}a,a:hover{color:var(--accent)}p{margin-bottom:1em}.prose p{margin-bottom:2em}textarea{width:100%;font-size:16px}input{font-size:16px}table{width:100%}img{max-width:100%;height:auto;border-radius:8px}code{padding:2px 5px;background-color:rgb(var(--gray-light));border-radius:2px}pre{padding:1.5em;border-radius:8px}pre>code{all:unset}blockquote{border-left:4px solid var(--accent);padding:0 0 0 20px;margin:0;font-size:1.333em}hr{border:none;border-top:1px solid rgb(var(--gray-light))}@media (max-width: 720px){body{font-size:18px}main{padding:1em}}.sr-only{border:0;padding:0;margin:0;position:absolute!important;height:1px;width:1px;overflow:hidden;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);clip-path:inset(50%);white-space:nowrap}.tag{display:inline-block;background-color:#f3f4f6;border-radius:.5rem;padding:.25rem .75rem;margin:0 .5rem .5rem 0;font-size:.875rem;font-weight:600;color:#4b5563}header[data-astro-cid-3ef6ksr2]{margin:0;padding:0 1em;background:#fff;box-shadow:0 2px 8px rgba(var(--black),5%)}h2[data-astro-cid-3ef6ksr2]{margin:0;font-size:1em}h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2],h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none}nav[data-astro-cid-3ef6ksr2]{display:flex;align-items:center;justify-content:space-between}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{padding:1em .5em;color:var(--black);border-bottom:4px solid transparent;text-decoration:none}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none;border-bottom-color:var(--accent)}.social-links[data-astro-cid-3ef6ksr2],.social-links[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{display:flex}@media (max-width: 720px){.social-links[data-astro-cid-3ef6ksr2]{display:none}}footer[data-astro-cid-sz7xmlte]{padding:2em 1em 6em;background:linear-gradient(var(--gray-gradient)) no-repeat;color:rgb(var(--gray));text-align:center}.social-links[data-astro-cid-sz7xmlte]{display:flex;justify-content:center;gap:1em;margin-top:1em}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]{text-decoration:none;color:rgb(var(--gray))}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]:hover{color:rgb(var(--gray-dark))}
a[data-astro-cid-eimmu3lg]{display:inline-block;text-decoration:none}a[data-astro-cid-eimmu3lg].active{font-weight:bolder;text-decoration:underline}
main[data-astro-cid-bvzihdzo]{width:calc(100% - 2em);max-width:100%;margin:0}.hero-image[data-astro-cid-bvzihdzo]{width:100%}.hero-image[data-astro-cid-bvzihdzo] img[data-astro-cid-bvzihdzo]{display:block;margin:0 auto;border-radius:12px;box-shadow:var(--box-shadow)}.prose[data-astro-cid-bvzihdzo]{width:720px;max-width:calc(100% - 2em);margin:auto;padding:1em;color:rgb(var(--gray-dark))}.title[data-astro-cid-bvzihdzo]{margin-bottom:1em;padding:1em 0;text-align:center;line-height:1}.title[data-astro-cid-bvzihdzo] h1[data-astro-cid-bvzihdzo]{margin:0 0 .5em}.date[data-astro-cid-bvzihdzo]{margin-bottom:.5em;color:rgb(var(--gray))}.last-updated-on[data-astro-cid-bvzihdzo]{font-style:italic}
[data-astro-image]{width:100%;height:auto;object-fit:var(--fit);object-position:var(--pos);aspect-ratio:var(--w) / var(--h)}[data-astro-image=responsive]{max-width:calc(var(--w) * 1px);max-height:calc(var(--h) * 1px)}[data-astro-image=fixed]{width:calc(var(--w) * 1px);height:calc(var(--h) * 1px)}
</style></head> <body data-astro-cid-bvzihdzo> <header data-astro-cid-3ef6ksr2> <nav data-astro-cid-3ef6ksr2> <h2 data-astro-cid-3ef6ksr2><a href="/" data-astro-cid-3ef6ksr2>Govind&#39;s Blog</a></h2> <div class="internal-links" data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Home </a>  <a href="/blog" class="active" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Blog </a>  <a href="/ideas" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Steal My Ideas </a>  <a href="/editor" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Image Editor </a>  </div> <div class="social-links" data-astro-cid-3ef6ksr2> <a href="https://x.com/DeepknowledgeU" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Follow Astro on X</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/twitter" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z" data-astro-cid-3ef6ksr2></path></svg> </a> <a href="https://github.com/Gowind" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>My Github</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/github" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-3ef6ksr2></path></svg> </a> </div> </nav> </header>  <main data-astro-cid-bvzihdzo> <article data-astro-cid-bvzihdzo> <div class="hero-image" data-astro-cid-bvzihdzo> <img width="1020" height="510" src="/blog-placeholder-5.jpg" alt="" data-astro-cid-bvzihdzo> </div> <div class="prose" data-astro-cid-bvzihdzo> <div class="title" data-astro-cid-bvzihdzo> <div class="date" data-astro-cid-bvzihdzo> <time datetime="2025-01-09T23:00:00.000Z"> Jan 10, 2025 </time>  </div> <h1 data-astro-cid-bvzihdzo>IS SIMD always faster ?</h1> <hr data-astro-cid-bvzihdzo> </div>  <p>All modern CPUS carry SIMD hardware units that software can exploit to run code even faster.
But does using SIMD mean our code is always faster ?</p>
<p>In this blog post, I write down about my experience trying to optimize an algorithm to use faster hardware and report the benchmarks and my conclusions.</p>
<p>TL;DR: it really depends on the algorithm, data size AND other subsystems of the CPU</p>
<h1 id="problem-context">Problem context</h1>
<p>I was tasked with coming up <a href="https://github.com/ashvardanian/SimSIMD/pull/239">with a benchmark for TF-IDF calculation</a></p>
<p>TF-IDF stands for “Term Frequency-Inverse Document Frequency”, a <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">statistical measure</a> for calculating the relevancy of words in a given piece of text.
The measure is a multiplication of 2 measures</p>
<ol>
<li>Term Frequency - The number of times a term (or a word) appears in a given piece of text</li>
<li>Inverse Document Frequency - a number derived inversely proportional to the number of times it appears in a given corpus</li>
</ol>
<p>A corpus is a dataset of text (say, a selected set of books or text that we use as our knowledge base)
The idea behind the <code>Inverse Document Frequency</code> is that words that appear more frequently in a text
have fewer information (words like: <code>a</code>,<code>the</code>, <code>for</code>, even <code>the</code>) encoded in them compared to words
that appear rarer. We can use the inverse of the logarithm of the frequency of a word in a given corpus to calculate the inverse document frequency
After reading through SciPy’s source code, this is the implementation of IDF I came up with:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="rust"><code><span class="line"><span style="color:#F97583">fn</span><span style="color:#B392F0"> calculate_idf</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">&#x26;mut</span><span style="color:#79B8FF"> self</span><span style="color:#E1E4E8">) {</span></span>
<span class="line"><span style="color:#6A737D">        // each unique word (token) in our corpus has a term_id</span></span>
<span class="line"><span style="color:#F97583">        for</span><span style="color:#E1E4E8"> term_id </span><span style="color:#F97583">in</span><span style="color:#79B8FF"> 0</span><span style="color:#F97583">..</span><span style="color:#79B8FF">self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">tokens</span><span style="color:#F97583">.</span><span style="color:#B392F0">len</span><span style="color:#E1E4E8">() {</span></span>
<span class="line"><span style="color:#F97583">            let</span><span style="color:#F97583"> mut</span><span style="color:#E1E4E8"> df </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#F97583">            for</span><span style="color:#E1E4E8"> document </span><span style="color:#F97583">in</span><span style="color:#79B8FF"> self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">documents</span><span style="color:#F97583">.</span><span style="color:#B392F0">iter</span><span style="color:#E1E4E8">() {</span></span>
<span class="line"><span style="color:#F97583">                if</span><span style="color:#E1E4E8"> document[term_id] </span><span style="color:#F97583">></span><span style="color:#79B8FF"> 0.0</span><span style="color:#E1E4E8"> {</span></span>
<span class="line"><span style="color:#E1E4E8">                    df </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">                }</span></span>
<span class="line"><span style="color:#E1E4E8">            }</span></span>
<span class="line"><span style="color:#F97583">            let</span><span style="color:#E1E4E8"> n_documents </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">documents</span><span style="color:#F97583">.</span><span style="color:#B392F0">len</span><span style="color:#E1E4E8">();</span></span>
<span class="line"><span style="color:#F97583">            let</span><span style="color:#E1E4E8"> present </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> df </span><span style="color:#F97583">as</span><span style="color:#B392F0"> f64</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#F97583">            let</span><span style="color:#E1E4E8"> idf </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> (((n_documents </span><span style="color:#F97583">+</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">as</span><span style="color:#B392F0"> f64</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">/</span><span style="color:#E1E4E8"> (present </span><span style="color:#F97583">+</span><span style="color:#79B8FF"> 1.0</span><span style="color:#E1E4E8">))</span><span style="color:#F97583">.</span><span style="color:#B392F0">ln</span><span style="color:#E1E4E8">() </span><span style="color:#F97583">+</span><span style="color:#79B8FF"> 1.0</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#79B8FF">            self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">idfs</span><span style="color:#F97583">.</span><span style="color:#B392F0">insert</span><span style="color:#E1E4E8">(term_id, idf);</span></span>
<span class="line"><span style="color:#E1E4E8">        }</span></span>
<span class="line"><span style="color:#E1E4E8">    }</span></span></code></pre>
<p>Given the mapping from a term to its IDF value, we can calculate the <code>TF-IDF</code> of any input text as a
vector (or array. Both terms are used interchangeably in this document)</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="rust"><code><span class="line"><span style="color:#F97583">    fn</span><span style="color:#B392F0"> tfidf_representation</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">&#x26;</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">, input</span><span style="color:#F97583">:</span><span style="color:#F97583"> &#x26;</span><span style="color:#B392F0">str</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">-></span><span style="color:#B392F0"> Vec</span><span style="color:#E1E4E8">&#x3C;</span><span style="color:#B392F0">f64</span><span style="color:#E1E4E8">> {</span></span>
<span class="line"><span style="color:#F97583">        let</span><span style="color:#F97583"> mut</span><span style="color:#E1E4E8"> row_vector </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vec!</span><span style="color:#E1E4E8">[</span><span style="color:#79B8FF">0.0</span><span style="color:#E1E4E8">; </span><span style="color:#79B8FF">self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">tokens</span><span style="color:#F97583">.</span><span style="color:#B392F0">len</span><span style="color:#E1E4E8">()];</span></span>
<span class="line"><span style="color:#F97583">        let</span><span style="color:#E1E4E8"> tokens </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> self</span><span style="color:#F97583">.</span><span style="color:#B392F0">tokenize</span><span style="color:#E1E4E8">(input);</span></span>
<span class="line"><span style="color:#F97583">        for</span><span style="color:#E1E4E8"> token </span><span style="color:#F97583">in</span><span style="color:#E1E4E8"> tokens</span><span style="color:#F97583">.</span><span style="color:#B392F0">iter</span><span style="color:#E1E4E8">() {</span></span>
<span class="line"><span style="color:#F97583">            let</span><span style="color:#E1E4E8"> term_id </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">tokens_index</span><span style="color:#F97583">.</span><span style="color:#B392F0">get</span><span style="color:#E1E4E8">(token)</span><span style="color:#F97583">.</span><span style="color:#B392F0">unwrap</span><span style="color:#E1E4E8">();</span></span>
<span class="line"><span style="color:#F97583">            let</span><span style="color:#E1E4E8"> term_idf </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">idfs</span><span style="color:#F97583">.</span><span style="color:#B392F0">get</span><span style="color:#E1E4E8">(term_id)</span><span style="color:#F97583">.</span><span style="color:#B392F0">unwrap</span><span style="color:#E1E4E8">();</span></span>
<span class="line"><span style="color:#E1E4E8">            row_vector[</span><span style="color:#F97583">*</span><span style="color:#E1E4E8">term_id] </span><span style="color:#F97583">+=</span><span style="color:#F97583"> *</span><span style="color:#E1E4E8">term_idf;</span></span>
<span class="line"><span style="color:#E1E4E8">        }</span></span>
<span class="line"><span style="color:#B392F0">        l2_normalize</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">&#x26;mut</span><span style="color:#E1E4E8"> row_vector);</span></span>
<span class="line"><span style="color:#F97583">        return</span><span style="color:#E1E4E8"> row_vector;</span></span>
<span class="line"><span style="color:#E1E4E8">    }</span></span></code></pre>
<p>The representation of any input text is a vector. The length of the vector = number of terms in our corpus.</p>
<p>Now that we have a vector representation of our document, we can use many measures to perform a “search”. For example, we can use cosine similiarity (among many others) to search for documents that might match our input query.</p>
<h2 id="problem">Problem</h2>
<p>While it is convenient to represent a piece of text as an array of numbers, the array is largely empty for most input queries, even documents.</p>
<p>As an example, assume that our corpus as 65000 unique words. In our TF-IDF representation, our arrays for each document will have 65000 elements in them, each multiplied by the frequency of the term in each document. An input document like “all our queries are belongs to us” has only 8 words, so except for maybe 8 locations, the array will be filled with 0s.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>vector_for_input = [0.0, 0.0, 0.0, 0.45, 0.12,...... 0.0, 0.0]'</span></span></code></pre>
<p>Assuming that we are using 4-byte floating point numbers to represent a tf-idf element, we are wasting
64996*4 = 259984 bytes (250KB!) per document just to represent the lack of a value. Even with 2 or 1 byte floating points, that is still ~128KB or ~64KB per document</p>
<h2 id="solutions">Solutions</h2>
<p>A common solution to this problem is to use Sparse Vectors. A Sparse vector is a data structure that stores only the non-zero elements and their indices. This way, we can avoid tracking indices that do not store any value.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>#[derive(Clone, Debug)]</span></span>
<span class="line"><span>struct SparseVector {</span></span>
<span class="line"><span>    indices: Vec&#x3C;u16>,</span></span>
<span class="line"><span>    values: Vec&#x3C;f32>,</span></span>
<span class="line"><span>}</span></span></code></pre>
<p>Since our corpus is made of only 65000 words, we can represent each term (thus index in our vectors) using a 2-byte u16. With a 4-byte floating point for each tf-idf value, our document representation now has a size of indices: (8x2) bytes + values: (8x4) bytes = 48 bytes ! Compare that to 64,128 or 256KB !</p>
<p>We can represent of our SparseVector situated in memory like this</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>         1 | 5 | 17 | 120 | 2013 | 4016 | 5123 | 101234 |</span></span>
<span class="line"><span>0xfffecd </span></span>
<span class="line"><span>         0.1 | 0.3 | 0.0112 | 0.0004 | 0.0076 | 0.0134 | 0.098 | 0.012 |</span></span>
<span class="line"><span>0xeeffecd   </span></span></code></pre>
<p>The hexadecimal suffixes are starting memory address for the array.
<strong>Note that the indices of the SparseVector are sorted</strong>. This is crucial, otherwise our algorithm won’t work.</p>
<p>With a SparseVector representation using sorted indices, it is easy to calculate the dot product against another SparseVector: We simply loop through the indices of both vectors and multiply the values of matching indices.
Since the indices are sorted, we can simply adjust the pointers as needed, without having to look for a matching index from the start of the indices array, thus calculating the dot product in linear (O(n)) time</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="rust"><code><span class="line"><span style="color:#F97583"> fn</span><span style="color:#B392F0"> sparse_dot_product</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">&#x26;</span><span style="color:#79B8FF">self</span><span style="color:#E1E4E8">, other</span><span style="color:#F97583">:</span><span style="color:#F97583"> &#x26;</span><span style="color:#B392F0">SparseVector</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">-></span><span style="color:#E1E4E8"> (</span><span style="color:#B392F0">u16</span><span style="color:#E1E4E8">, </span><span style="color:#B392F0">f64</span><span style="color:#E1E4E8">) {</span></span>
<span class="line"><span style="color:#F97583">        let</span><span style="color:#F97583"> mut</span><span style="color:#E1E4E8"> result </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 0.0</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#F97583">        let</span><span style="color:#F97583"> mut</span><span style="color:#E1E4E8"> i </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#F97583">        let</span><span style="color:#F97583"> mut</span><span style="color:#E1E4E8"> j </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#F97583">        let</span><span style="color:#F97583"> mut</span><span style="color:#E1E4E8"> matches</span><span style="color:#F97583">:</span><span style="color:#B392F0"> u16</span><span style="color:#F97583"> =</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#F97583">        while</span><span style="color:#E1E4E8"> i </span><span style="color:#F97583">&#x3C;</span><span style="color:#79B8FF"> self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">indices</span><span style="color:#F97583">.</span><span style="color:#B392F0">len</span><span style="color:#E1E4E8">() </span><span style="color:#F97583">&#x26;&#x26;</span><span style="color:#E1E4E8"> j </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> other</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">indices</span><span style="color:#F97583">.</span><span style="color:#B392F0">len</span><span style="color:#E1E4E8">() {</span></span>
<span class="line"><span style="color:#F97583">            if</span><span style="color:#79B8FF"> self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">indices[i] </span><span style="color:#F97583">==</span><span style="color:#E1E4E8"> other</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">indices[j] {</span></span>
<span class="line"><span style="color:#E1E4E8">                matches </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">                result </span><span style="color:#F97583">+=</span><span style="color:#B392F0"> f64</span><span style="color:#F97583">::</span><span style="color:#B392F0">from</span><span style="color:#E1E4E8">( </span><span style="color:#79B8FF">self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">values[i] </span><span style="color:#F97583">*</span><span style="color:#E1E4E8"> other</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">values[j]);</span></span>
<span class="line"><span style="color:#E1E4E8">                i </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">                j </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">            } </span><span style="color:#F97583">else</span><span style="color:#F97583"> if</span><span style="color:#79B8FF"> self</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">indices[i] </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> other</span><span style="color:#F97583">.</span><span style="color:#E1E4E8">indices[j] {</span></span>
<span class="line"><span style="color:#E1E4E8">                i </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">            } </span><span style="color:#F97583">else</span><span style="color:#E1E4E8"> {</span></span>
<span class="line"><span style="color:#E1E4E8">                j </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 1</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">            }</span></span>
<span class="line"><span style="color:#E1E4E8">        }</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">        (matches, result)</span></span>
<span class="line"><span style="color:#E1E4E8">    }</span></span></code></pre>
<h2 id="simd-ification">SIMD-ification</h2>
<p>This algorithm looks ripe for trying to use SIMD instructions to accelerate the task of matching the indices. I will keep this post restricted to just the NEON instruction set ,as it is the most common SIMD instruction set on ARM and is available on pretty much everything from Rpi to Apple’s M4.</p>
<p>ARM has newer instruction sets like SVE and SVE2, but those are rare to find (outside of expensive server chips like Graviton4) and <a href="https://scalable.uni-jena.de/opt/sme/micro.html">early benchmarks of SVE on the M4</a> macs indicated that the throughput of SVE is often same or slower than using NEON</p>
<p>A quick introduction to NEON for the readers incase they aren’t aware : NEON registers are 128-bits wide. The registers can be split into lanes that are each 8/16/32/64 wide depending on the instructions used and the data. We can load 8 2-byte indices into a single NEON register like so:</p>
<p>The following code is written in C using <a href="https://arm-software.github.io/acle/neon_intrinsics/advsimd.html">NEON intrinsincs</a></p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#79B8FF">uint16x8_t</span><span style="color:#E1E4E8"> a_vec, b_vec;</span></span>
<span class="line"><span style="color:#E1E4E8">a_vec </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vld1q_u16</span><span style="color:#E1E4E8">(a) ;</span><span style="color:#6A737D"> // loads 8 u16 values starting at address pointed by pointer a</span></span>
<span class="line"><span style="color:#E1E4E8">b_vec </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vld1q_u16</span><span style="color:#E1E4E8">(b) ;</span></span></code></pre>
<p>To load the corresponding weights, we need to use 2 NEON registers/variables per vector, as we are using 4-byte floating point values and to store 8 FP values, we need 4*8 bytes = 256 bytes, thus 2 NEON registers</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#79B8FF">float32x4_t</span><span style="color:#E1E4E8"> a_weights_vec_low </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vld1q_f32</span><span style="color:#E1E4E8">(a_weights);</span></span>
<span class="line"><span style="color:#79B8FF">float32x4_t</span><span style="color:#E1E4E8"> a_weights_vec_high </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vld1q_f32</span><span style="color:#E1E4E8">(a_weights </span><span style="color:#F97583">+</span><span style="color:#79B8FF"> 4</span><span style="color:#E1E4E8">);</span></span></code></pre>
<p>How can we attempt to speed up our algorithm using SIMD ? Taking a page from Ash Vardanian’s <a href="https://ashvardanian.com/posts/simd-set-intersections-sve2-avx512/#simd">absolutely fantastic intro on Set intersections</a> I tried to implement set intersections with weights for my
SparseVector Dot Product implementation</p>
<p>The idea is as follows:</p>
<ol>
<li>In batches of 8, load indices from vectors a and b.</li>
<li>In each batch, attempt to find matching indices</li>
<li>If found, compute the product of the corresponding weights from the weights_vector</li>
</ol>
<p>Since there are no native set intersection instructions in NEON, we have to emulate this ourselves.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>a : | 3 | 7 | 9 | 15 | 18 | 22 | 34 | 57 |</span></span>
<span class="line"><span>b : | 0 | 1 | 2 | 3  | 9  | 23 | 32 | 36 | </span></span></code></pre>
<p>In this batch, indices 3 and 9 match in both vectors. We thus multiple a_weights[0] * b_weights[3] and a_weights[2] * b_weights[4]</p>
<p>My code runs a loop for each batch, where each element in <code>b</code> is compared to all the elements in <code>a</code> during every iteration. If we find a match somewhere, then the corresponding weights are multiplied</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">for</span><span style="color:#E1E4E8"> (</span><span style="color:#F97583">int</span><span style="color:#E1E4E8"> lane </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">; lane </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> register_size; lane</span><span style="color:#F97583">++</span><span style="color:#E1E4E8">) {</span></span>
<span class="line"><span style="color:#F97583">        uint16_t</span><span style="color:#E1E4E8"> elem </span><span style="color:#F97583">=</span><span style="color:#B392F0"> EXT_LANE_U16</span><span style="color:#E1E4E8">(b_vec, lane);</span></span>
<span class="line"><span style="color:#79B8FF">         uint16x8_t</span><span style="color:#E1E4E8"> compare_vec </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vceqq_u16</span><span style="color:#E1E4E8">(a_vec, </span><span style="color:#B392F0">vdupq_n_u16</span><span style="color:#E1E4E8">(elem));</span></span>
<span class="line"><span style="color:#F97583">        uint16_t</span><span style="color:#E1E4E8"> has_matches </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vaddvq_u16</span><span style="color:#E1E4E8">(compare_vec);</span></span>
<span class="line"><span style="color:#F97583">        if</span><span style="color:#E1E4E8">(has_matches </span><span style="color:#F97583">==</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">) {</span></span>
<span class="line"><span style="color:#F97583">          continue</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">        }</span></span>
<span class="line"><span style="color:#79B8FF">         uint16x4_t</span><span style="color:#E1E4E8"> matches_low </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vget_low_u16</span><span style="color:#E1E4E8">(compare_vec);</span></span>
<span class="line"><span style="color:#79B8FF">         uint16x4_t</span><span style="color:#E1E4E8"> matches_high </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vget_high_u16</span><span style="color:#E1E4E8">(compare_vec);</span></span>
<span class="line"><span style="color:#79B8FF">         uint32x4_t</span><span style="color:#E1E4E8"> masks_low </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vmovl_s16</span><span style="color:#E1E4E8">(matches_low);</span></span>
<span class="line"><span style="color:#79B8FF">         uint32x4_t</span><span style="color:#E1E4E8"> masks_high </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vmovl_s16</span><span style="color:#E1E4E8">(matches_high);</span></span>
<span class="line"><span style="color:#F97583">         float</span><span style="color:#E1E4E8"> b_weight </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> lane </span><span style="color:#F97583">&#x3C;</span><span style="color:#79B8FF"> 4</span><span style="color:#F97583"> ?</span></span>
<span class="line"><span style="color:#B392F0">             EXTRACT_LANE_F32</span><span style="color:#E1E4E8">(b_weights_vec_low, lane) </span><span style="color:#F97583">:</span></span>
<span class="line"><span style="color:#B392F0">             EXTRACT_LANE_F32</span><span style="color:#E1E4E8">(b_weights_vec_high, lane </span><span style="color:#F97583">-</span><span style="color:#79B8FF"> 4</span><span style="color:#E1E4E8">);</span></span>
<span class="line"><span style="color:#79B8FF">         float32x4_t</span><span style="color:#E1E4E8"> b_weights </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vdupq_n_f32</span><span style="color:#E1E4E8">(b_weight);</span></span>
<span class="line"><span style="color:#79B8FF">         float32x4_t</span><span style="color:#E1E4E8"> bl </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vbslq_f32</span><span style="color:#E1E4E8">(masks_low, b_weights, zeroes);</span></span>
<span class="line"><span style="color:#79B8FF">         float32x4_t</span><span style="color:#E1E4E8"> bh </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vbslq_f32</span><span style="color:#E1E4E8">(masks_high, b_weights, zeroes);</span></span>
<span class="line"><span style="color:#79B8FF">         float32x4_t</span><span style="color:#E1E4E8"> weights_product_low </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vmulq_f32</span><span style="color:#E1E4E8">(bl, a_weights_vec_low);</span></span>
<span class="line"><span style="color:#79B8FF">         float32x4_t</span><span style="color:#E1E4E8"> weights_product_high </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vmulq_f32</span><span style="color:#E1E4E8">(bh, a_weights_vec_high);</span></span>
<span class="line"><span style="color:#E1E4E8">         total_product </span><span style="color:#F97583">+=</span><span style="color:#B392F0"> vaddvq_f32</span><span style="color:#E1E4E8">(weights_product_low);</span></span>
<span class="line"><span style="color:#E1E4E8">         total_product </span><span style="color:#F97583">+=</span><span style="color:#B392F0"> vaddvq_f32</span><span style="color:#E1E4E8">(weights_product_high);</span></span>
<span class="line"><span style="color:#F97583">         uint16_t</span><span style="color:#E1E4E8"> upper_intersections </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vaddv_u16</span><span style="color:#E1E4E8">(</span><span style="color:#B392F0">vshr_n_u16</span><span style="color:#E1E4E8">(matches_low, </span><span style="color:#79B8FF">15</span><span style="color:#E1E4E8">));</span></span>
<span class="line"><span style="color:#F97583">         uint16_t</span><span style="color:#E1E4E8"> lower_intersections </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vaddv_u16</span><span style="color:#E1E4E8">(</span><span style="color:#B392F0">vshr_n_u16</span><span style="color:#E1E4E8">(matches_high, </span><span style="color:#79B8FF">15</span><span style="color:#E1E4E8">));</span></span>
<span class="line"><span style="color:#E1E4E8">         intersection_size </span><span style="color:#F97583">+=</span><span style="color:#E1E4E8"> upper_intersections;</span></span>
<span class="line"><span style="color:#E1E4E8">         intersection_size </span><span style="color:#F97583">+=</span><span style="color:#E1E4E8"> lower_intersections;</span></span></code></pre>
<p>The above loop can be quite a bit to grok all at once, so lets break it down into smaller chunks</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">for</span><span style="color:#E1E4E8"> (</span><span style="color:#F97583">int</span><span style="color:#E1E4E8"> lane </span><span style="color:#F97583">=</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">; lane </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> register_size; lane</span><span style="color:#F97583">++</span><span style="color:#E1E4E8">) {</span></span>
<span class="line"><span style="color:#F97583">  uint16_t</span><span style="color:#E1E4E8"> elem </span><span style="color:#F97583">=</span><span style="color:#B392F0"> EXT_LANE_U16</span><span style="color:#E1E4E8">(b_vec, lane);</span></span>
<span class="line"><span style="color:#79B8FF">  uint16x8_t</span><span style="color:#E1E4E8"> compare_vec </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vceqq_u16</span><span style="color:#E1E4E8">(a_vec, </span><span style="color:#B392F0">vdupq_n_u16</span><span style="color:#E1E4E8">(elem));</span></span></code></pre>
<p><code>register_size</code> is 8 (8 16-bit indices). We iterate through each lane in our SIMD register and load the element of that lane into <code>elem</code>.
<code>vdupq_n_u16(elem)</code> results in a SIMD value of type uin16x8_t, where each lane lane is duplicated with the same value.
We then compare it lane-wise with our <code>a_vec</code> using <code>vceqq_u16</code> , resulting in a SIMD value with each lane being <code>1</code> , indicating a match, or a <code>0</code> indicating mismatch.
So if we compare 2 vectors like the following using <code>vceqq_u16</code></p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>a : | 3 | 7 | 9 | 15 | 18 | 22 | 34 | 57 |</span></span>
<span class="line"><span>b : | 3 | 3 | 3 | 3  | 3  | 3 |  3  |  3 | </span></span></code></pre>
<p>we will get a result like</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>res: | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |</span></span></code></pre>
<p>I used a quick shortcut to check if there are no matches: I first added all the values of the lanes in res, to see if they are 0, using <code>vaddvq_u16</code>. If the sum of all lanes in <code>res</code> is 0, then it means that none of the lanes contained <code>elem</code>, so we can quickly move on to the next iteration of the loop</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">uint16_t</span><span style="color:#E1E4E8"> has_matches </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vaddvq_u16</span><span style="color:#E1E4E8">(compare_vec);</span></span>
<span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8">(has_matches </span><span style="color:#F97583">==</span><span style="color:#79B8FF"> 0</span><span style="color:#E1E4E8">) {</span></span>
<span class="line"><span style="color:#F97583">  continue</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre>
<p>If the sum > 0, then we do have a match in one of the lanes. How do we figure out which lanes have a match, but do so without running yet another loop ? That’s the core trick in my code !</p>
<p>Since our indices are 16 bits, but our weights are 32 bits (floating points), we can only load 4 weights per SIMD value. So we need 2 <code>float32x4_t</code> SIMD variables to represent the weights of each vector in every batch:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#79B8FF">    float32x4_t</span><span style="color:#E1E4E8"> a_weights_vec_low </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vld1q_f32</span><span style="color:#E1E4E8">(a_weights);</span></span>
<span class="line"><span style="color:#79B8FF">    float32x4_t</span><span style="color:#E1E4E8"> a_weights_vec_high </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vld1q_f32</span><span style="color:#E1E4E8">(a_weights </span><span style="color:#F97583">+</span><span style="color:#79B8FF"> 4</span><span style="color:#E1E4E8">);</span></span></code></pre>
<p>To make it easier to work with 2 split weight variables, we also split <code>compare_vec</code> into 2, each consisting of the upper and lower 4 lanes respectively:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#79B8FF">uint16x4_t</span><span style="color:#E1E4E8"> matches_low </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vget_low_u16</span><span style="color:#E1E4E8">(compare_vec);</span><span style="color:#6A737D"> // lower 4 lanes</span></span>
<span class="line"><span style="color:#79B8FF">uint16x4_t</span><span style="color:#E1E4E8"> matches_high </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vget_high_u16</span><span style="color:#E1E4E8">(compare_vec);</span><span style="color:#6A737D"> // upper 4 lanes</span></span>
<span class="line"><span style="color:#79B8FF">uint32x4_t</span><span style="color:#E1E4E8"> masks_low </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vmovl_s16</span><span style="color:#E1E4E8">(matches_low);</span><span style="color:#6A737D"> // sign extend each lane from 16-bit to 32-bits </span></span>
<span class="line"><span style="color:#79B8FF">uint32x4_t</span><span style="color:#E1E4E8"> masks_high </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vmovl_s16</span><span style="color:#E1E4E8">(matches_high);</span><span style="color:#6A737D"> // sign extend</span></span></code></pre>
<p>the <code>compare_vec</code> vector results in 2 mask vectors of 4 32-bit integer each.
The <code>vmovl_s16</code> inst. sign extends each lane, converting our 16-bit integer to a 32-bit integer</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>compare_vec: | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 |</span></span>
<span class="line"><span>matches_low:  | 0 | 0 | 0 | 0 |</span></span>
<span class="line"><span>matches_high: | 1 | 0 | 0 | 0 | </span></span>
<span class="line"><span>masks_low:  | ...0000 | 0 | 0 | 0 | // 4 32-bit integers</span></span>
<span class="line"><span>masks_high: | ...1111 | 0 | 0 | 0 | </span></span></code></pre>
<p><code>a_weights_vec_low</code> and <code>a_weights_vec_high</code> contain the lower and upper weights of our <code>a_vec</code>.
<code>masks_low</code> and <code>masks_high</code> indicate if <code>elem</code> of <code>b_vec</code> has a match in the lower and upper halves of <code>a_vec</code>.</p>
<p>Using this we can calculate the dot product of the matching elements, without having to iterate through the lanes of <code>res</code> or <code>masks_low</code> or <code>masks_high</code> variables using the mask variables</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">float</span><span style="color:#E1E4E8"> b_weight </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> lane </span><span style="color:#F97583">&#x3C;</span><span style="color:#79B8FF"> 4</span><span style="color:#F97583"> ?</span></span>
<span class="line"><span style="color:#B392F0">    EXTRACT_LANE_F32</span><span style="color:#E1E4E8">(b_weights_vec_low, lane) </span><span style="color:#F97583">:</span></span>
<span class="line"><span style="color:#B392F0">    EXTRACT_LANE_F32</span><span style="color:#E1E4E8">(b_weights_vec_high, lane </span><span style="color:#F97583">-</span><span style="color:#79B8FF"> 4</span><span style="color:#E1E4E8">);</span><span style="color:#6A737D"> // extract the weight corresponding to elem from b</span></span>
<span class="line"><span style="color:#E1E4E8">    </span></span>
<span class="line"><span style="color:#79B8FF">float32x4_t</span><span style="color:#E1E4E8"> zeroes </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vdupq_n_f32</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">0.0</span><span style="color:#E1E4E8">);</span><span style="color:#6A737D"> // a vector with just 0.0 in all lanes</span></span>
<span class="line"><span style="color:#79B8FF">float32x4_t</span><span style="color:#E1E4E8"> b_weights </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vdupq_n_f32</span><span style="color:#E1E4E8">(b_weight);</span><span style="color:#6A737D"> // vector with all lanes duplicated to b_weight</span></span>
<span class="line"><span style="color:#79B8FF">float32x4_t</span><span style="color:#E1E4E8"> bl </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vbslq_f32</span><span style="color:#E1E4E8">(masks_low, b_weights, zeroes);</span><span style="color:#6A737D"> // if mask lane = 1, then </span></span>
<span class="line"><span style="color:#79B8FF">float32x4_t</span><span style="color:#E1E4E8"> bh </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vbslq_f32</span><span style="color:#E1E4E8">(masks_high, b_weights, zeroes);</span></span>
<span class="line"><span style="color:#79B8FF">float32x4_t</span><span style="color:#E1E4E8"> weights_product_low </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vmulq_f32</span><span style="color:#E1E4E8">(bl, a_weights_vec_low);</span></span>
<span class="line"><span style="color:#79B8FF">float32x4_t</span><span style="color:#E1E4E8"> weights_product_high </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vmulq_f32</span><span style="color:#E1E4E8">(bh, a_weights_vec_high);</span></span></code></pre>
<p>We use the masks to mask out (zero) lanes, where mask is 0, using the <code>vbslq_f32</code> (bit select) intrinsic. Essentially it works like this:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>masks_high: | ...1111 | ...0   | ...0 | ...0 | masks_high: | ...0 | ...0   | ...0 | ...0 | </span></span>
<span class="line"><span>b_weights:  | 1100111 | .111   | .101 | .111 | b_weights:  | 0000 | .111   | .101 | .111 | </span></span>
<span class="line"><span>bh          | 1100111 | 0000   | 0000 | 0000 | bl          | 0000 | 0000   | 0000 | 0000 | </span></span></code></pre>
<p>If there is a match between lane 7 of <code>a_vec</code>, and <code>elem</code> of <code>b_vec</code> , masks_high will have all <code>1</code>s in lane 3 of masks_high. After using
bit select, only that lane of <code>bl</code> will have the corresponding weight bets sets; all the other lanes will have a zero weight.</p>
<p>When we multiply this with the weights of <code>a_vec</code> split into <code>a_weights_vec_low</code> and <code>a_weights_vec_high</code>, we will ensure that only the values of the matching lanes are multiplied.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>bh             | 1100111 | 0000   | 0000 | 0000 | bl             | 0000 | 0000   | 0000 | 0000 |  </span></span>
<span class="line"><span>                                                X</span></span>
<span class="line"><span>a_w_high       | 1100001 | 0110   | 0000 | 1111 | a_w_high       | 1101 | 0110   | 1001 | 1111 | </span></span>
<span class="line"><span>result         | xxxxxxx | 0000   | 0000 | 0000 |                | 0000 | 0000   | 0000 | 0000 | </span></span></code></pre>
<p>Since all the indices in a Sparse Vectore are unique, we can be sure that only one lane of the resulting vectors (<code>weights_product_high</code> and <code>weights_product_low</code>) will have a resulting value. Therefore we can safely sum up both the vectors to get the product of indices of matching lanes</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#E1E4E8">total_product </span><span style="color:#F97583">+=</span><span style="color:#B392F0"> vaddvq_f32</span><span style="color:#E1E4E8">(weights_product_low);</span></span>
<span class="line"><span style="color:#E1E4E8">total_product </span><span style="color:#F97583">+=</span><span style="color:#B392F0"> vaddvq_f32</span><span style="color:#E1E4E8">(weights_product_high);</span></span></code></pre>
<p>Similarly, to track the total number of matched indices, we can sum across the masks vector</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#6A737D">// vshr_n_16 is a shift right operation. If our mask is all 111s, then shifting right by 15, will leave just a 1 in the LSB</span></span>
<span class="line"><span style="color:#6A737D">// indicating the count of match in that lane (which is 1)</span></span>
<span class="line"><span style="color:#F97583">uint16_t</span><span style="color:#E1E4E8"> upper_intersections </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vaddv_u16</span><span style="color:#E1E4E8">(</span><span style="color:#B392F0">vshr_n_u16</span><span style="color:#E1E4E8">(matches_low, </span><span style="color:#79B8FF">15</span><span style="color:#E1E4E8">)); </span></span>
<span class="line"><span style="color:#F97583">uint16_t</span><span style="color:#E1E4E8"> lower_intersections </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vaddv_u16</span><span style="color:#E1E4E8">(</span><span style="color:#B392F0">vshr_n_u16</span><span style="color:#E1E4E8">(matches_high, </span><span style="color:#79B8FF">15</span><span style="color:#E1E4E8">));</span></span>
<span class="line"><span style="color:#E1E4E8">intersection_size </span><span style="color:#F97583">+=</span><span style="color:#E1E4E8"> upper_intersections;</span></span>
<span class="line"><span style="color:#E1E4E8">intersection_size </span><span style="color:#F97583">+=</span><span style="color:#E1E4E8"> lower_intersections;</span></span></code></pre>
<p>In summary, we did the following:</p>
<ol>
<li>Batch process our SparseVector as 8 elements in each batch</li>
<li>Load weights for each vector / batch into 2 SIMD variables</li>
<li>Loop over each lane in <code>b_vec</code> and compare against all lanes in <code>a</code>.</li>
<li>Use mask vecs to multiply weights of only the matchings lanes</li>
</ol>
<p>Once we are done processing a batch (end of our initial <code>for</code> loop), we need to figure out how to advance our array pointers to load
the next batch.</p>
<p>Recall our initial batch:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>a : | 3 | 7 | 9 | 15 | 18 | 22 | 34 | 57 |</span></span>
<span class="line"><span>b : | 0 | 1 | 2 | 3  | 9  | 23 | 32 | 36 | </span></span></code></pre>
<p>After comparing all elements in b with a, how should we proceed to advance <code>*a</code> and <code>*b</code> ?
max(b) is 36 and max(a) is 57. Since our vectors are sorted, we can be assured that we won’t find 36 in the subsequent batches of a anymore.
We can thus safely increment b by 8 elements (b + 8).</p>
<p>For a, since <code>max(b) &#x3C; max(a)</code> , we advance <code>a</code> such that <code>a</code> points to the first element > <code>max(b)</code>. In this case, it is 57, so our next load of 8 elements will start at <code>a + 7</code> that is <code>a + 7</code>.</p>
<p>The lines after the for loop advance the pointers using this logic:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">uint8_t</span><span style="color:#E1E4E8"> askips </span><span style="color:#F97583">=</span><span style="color:#B392F0"> skips</span><span style="color:#E1E4E8">(a_vec, b_max);</span></span>
<span class="line"><span style="color:#E1E4E8">a </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 8</span><span style="color:#F97583"> -</span><span style="color:#E1E4E8"> askips;</span></span>
<span class="line"><span style="color:#F97583">uint8_t</span><span style="color:#E1E4E8"> bskips </span><span style="color:#F97583">=</span><span style="color:#B392F0"> skips</span><span style="color:#E1E4E8">(b_vec, a_max);</span></span>
<span class="line"><span style="color:#E1E4E8">b </span><span style="color:#F97583">+=</span><span style="color:#79B8FF"> 8</span><span style="color:#F97583"> -</span><span style="color:#E1E4E8"> bskips;</span></span></code></pre>
<p>I implemented the <code>skips</code> fn using intrinsics:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">inline</span><span style="color:#F97583"> uint8_t</span><span style="color:#B392F0"> skips</span><span style="color:#E1E4E8">(</span><span style="color:#79B8FF">uint16x8_t</span><span style="color:#FFAB70"> indexes</span><span style="color:#E1E4E8">, </span><span style="color:#F97583">uint16_t</span><span style="color:#FFAB70"> max</span><span style="color:#E1E4E8">) {</span></span>
<span class="line"><span style="color:#79B8FF">     uint16x8_t</span><span style="color:#E1E4E8"> smaller_elements </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vcleq_u16</span><span style="color:#E1E4E8">(indexes, </span><span style="color:#B392F0">vdupq_n_u16</span><span style="color:#E1E4E8">(max));</span><span style="color:#6A737D"> // lane =  if indexes[lane] &#x3C; = dup[lane]</span></span>
<span class="line"><span style="color:#79B8FF">     uint8x8_t</span><span style="color:#E1E4E8">  low_bits </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vshrn_n_u16</span><span style="color:#E1E4E8">(smaller_elements, </span><span style="color:#79B8FF">8</span><span style="color:#E1E4E8">);</span></span>
<span class="line"><span style="color:#F97583">     uint64_t</span><span style="color:#E1E4E8"> results </span><span style="color:#F97583">=</span><span style="color:#B392F0"> vreinterpret_u64_u8</span><span style="color:#E1E4E8">(high_bits);</span></span>
<span class="line"><span style="color:#F97583">     int</span><span style="color:#E1E4E8"> leading_zeroes </span><span style="color:#F97583">=</span><span style="color:#B392F0"> __builtin_clzl</span><span style="color:#E1E4E8">(results);</span></span>
<span class="line"><span style="color:#F97583">     return</span><span style="color:#E1E4E8"> leading_zeroes </span><span style="color:#F97583">/</span><span style="color:#79B8FF"> 8</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span></code></pre>
<p>We compare <code>max</code> with each index in <code>indexes</code>. A lane in smaller elements is set to all 1s if max >= indexes[lane] else 0.
We then extract the lower most 8-bits of each lane using <code>vshrn_n_u16</code> (shift right intrinsic) and then consolidated all the 8, 8-bit lanes
into a single 64-bit <code>results</code>.  We then count the number of leading zero bits using the builtin function <code>__builtin_clzl</code>. Note that
higher indexes are loaded in the upper lanes, so the MSB of results will contain the result of comparing max(a) with max(b).</p>
<p>I took a snapshot of the debugger to better visualize this :</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>* thread #1, queue = 'com.apple.main-thread', stop reason = step over</span></span>
<span class="line"><span>    frame #0: 0x0000000100003eac my`skips(indexes=([0] = 3, [1] = 7, [2] = 9, [3] = 15, [4] = 18, [5] = 22, [6] = 34, [7] = 57), max=36) at my.c:10:13</span></span>
<span class="line"><span>   7   	     uint8x8_t  low_bits = vshrn_n_u16(smaller_elements, 8);</span></span>
<span class="line"><span>   8   	     uint64_t results = vreinterpret_u64_u8(low_bits);</span></span>
<span class="line"><span>   9   	     int leading_zeroes = __builtin_clzl(results);</span></span>
<span class="line"><span>-> 10  	     return leading_zeroes / 8;</span></span>
<span class="line"><span>   11  	}</span></span>
<span class="line"><span>   12</span></span>
<span class="line"><span>   13  	int main() {</span></span>
<span class="line"><span>(lldb) frame variable</span></span>
<span class="line"><span>(uint16x8_t) indexes = (3, 7, 9, 15, 18, 22, 34, 57)</span></span>
<span class="line"><span>(uint16_t) max = 36</span></span>
<span class="line"><span>(uint16x8_t) smaller_elements = (65535, 65535, 65535, 65535, 65535, 65535, 65535, 0)</span></span>
<span class="line"><span>(uint8x8_t) low_bits = (0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00)</span></span>
<span class="line"><span>(uint64_t) results = 0x00ffffffffffffff</span></span>
<span class="line"><span>(int) leading_zeroes = 8</span></span></code></pre>
<p>We divide by 8 in the last line as each element is represented by 8-bits (hence / 8)</p>
<p>Since only one element in > max(b) , we therefore skip <code>a</code> by 8-1 = 7 indexes.</p>
<h2 id="results">Results</h2>
<p>I just described rather arduously, the long way towards SIMDifying the algorithm. Did it speedup my code tremendously ?
Sadly no. The algorithm doesn’t seem to be that much faster than the straightforward 20 lines of Rust code. Running some benchmarks here are the results on my M2 Mac Pro, the SIMD code is sometimes fast, but more often slower or sometimes only just a little bit better than the plain version</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="bash"><code><span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 166</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 187</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 141</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 195</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 183</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 174</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 254</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 216</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  64</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 137</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 346</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 345</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 191</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 491</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 375</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 370</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 429</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 399</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  128</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 295</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1354</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1346</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1404</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1299</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1470</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1454</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1408</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1504</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  512</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1395</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2795</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2766</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2754</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2858</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2650</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2783</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2929</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2904</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  1024</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2916</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5433</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5487</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 8,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5337</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5591</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5549</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 16,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5479</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5729</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5666</span></span>
<span class="line"><span style="color:#B392F0">plain</span><span style="color:#9ECBFF"> dot</span><span style="color:#9ECBFF"> product:</span><span style="color:#79B8FF">  2048</span><span style="color:#9ECBFF"> against</span><span style="color:#9ECBFF"> 32,</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5921</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 6654</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 187</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 362</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 325</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 308</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 287</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 279</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 258</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 64</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 291</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 800</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 833</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 854</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 737</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 471</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 600</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 445</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 412</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 128</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 479</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 3000</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2708</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2470</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1700</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2000</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1616</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1008</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1362</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 512</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1191</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 6492</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 6179</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 3333</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 3675</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5908</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 5704</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2587</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 2166</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 1024</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 1820</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 10437</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 6620</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 8</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 8816</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 10650</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 9462</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 16</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 11429</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 6304</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 3392</span></span>
<span class="line"><span style="color:#B392F0">NEON:</span><span style="color:#79B8FF"> 2048</span><span style="color:#9ECBFF"> vs</span><span style="color:#79B8FF"> 32</span><span style="color:#9ECBFF"> avg</span><span style="color:#9ECBFF"> elapsed_time</span><span style="color:#9ECBFF"> ns:</span><span style="color:#79B8FF"> 4395</span></span></code></pre>
<p>One of the reasons could be that the storing the indices and the values as continuous arrays makes the serial algorith extremely cache friendly, and all the duping lanes and masking instructions are simply too much of an overhead vs just reading the values from cache. Also SIMD instructions are not cheap and certain instructions might have way more latency than their serial counterparts. I lack a good way yet to benchmark the latency of NEON instructions on the Mac, so until then I can only speculate why the serial version in this case is better.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Trying to SIMD-ify an algorithm is an extremely worthwhile exercise and lesson in computers and programming. I still believe there is a lot of scope in trying to improve the algorith or optimize the instructions as I am by no means an expert on this subject. The result was a bit disappointing, but not really surprising. It reinforced the notion that just because your code is running on SIMD hardware doesnt mean that your code is running faster. As always, write, measure and observe instead of just making assumptions 😀. </p>
<p>You can <a href="https://github.com/ashvardanian/SimSIMD/pull/239/files#diff-52d4e3b03783dcd889732bda34db1f65d8713f189ce1d0e3ac56e48e21eafb6f">find the code for this post here on my Github</a></p>  </div> </article> </main> <footer data-astro-cid-sz7xmlte> <div class="social-links" data-astro-cid-sz7xmlte> <a href="https://x.com/DeepknowledgeU" target="_blank" data-astro-cid-sz7xmlte> <span class="sr-only" data-astro-cid-sz7xmlte>Follow Astro on X</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/twitter" data-astro-cid-sz7xmlte><path fill="currentColor" d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z" data-astro-cid-sz7xmlte></path></svg> </a> <a href="https://github.com/Gowind" target="_blank" data-astro-cid-sz7xmlte> <span class="sr-only" data-astro-cid-sz7xmlte>My Github</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/github" data-astro-cid-sz7xmlte><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-sz7xmlte></path></svg> </a> </div> </footer>  </body></html>