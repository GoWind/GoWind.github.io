<!DOCTYPE html><html lang="en" data-astro-cid-bvzihdzo> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><meta name="generator" content="Astro v5.9.1"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/saiyan_sans/Saiyan-Sans.ttf" as="font" type="font/ttf" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://gowind.github.io/blog/simd_algos_part2/"><!-- Primary Meta Tags --><title>SIMD algos part II: popcount</title><meta name="title" content="SIMD algos part II: popcount"><meta name="description" content><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://gowind.github.io/blog/simd_algos_part2/"><meta property="og:title" content="SIMD algos part II: popcount"><meta property="og:description" content><meta property="og:image" content="https://gowind.github.io/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://gowind.github.io/blog/simd_algos_part2/"><meta property="twitter:title" content="SIMD algos part II: popcount"><meta property="twitter:description" content><meta property="twitter:image" content="https://gowind.github.io/blog-placeholder-1.jpg"><!-- Cloudflare Web Analytics --><script defer src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;4de85a62d838459fafd8a042c2f1c7c2&quot;}"></script><!-- End Cloudflare Web Analytics --><style>:root{--accent: #2337ff;--accent-dark: #000d8a;--black: 15, 18, 25;--gray: 96, 115, 159;--gray-light: 229, 233, 240;--gray-dark: 34, 41, 57;--gray-gradient: rgba(var(--gray-light), 50%), #fff;--box-shadow: 0 2px 6px rgba(var(--gray), 25%), 0 8px 24px rgba(var(--gray), 33%), 0 16px 32px rgba(var(--gray), 33%)}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-regular.woff) format("woff");font-weight:400;font-style:normal;font-display:swap}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-bold.woff) format("woff");font-weight:700;font-style:normal;font-display:swap}@font-face{font-family:SaiyanSans;src:url(/js/Saiyan-Sans.HVcRaXbq.ttf) format("truetype");font-weight:400;font-style:normal;font-display:swap}body{font-family:Atkinson,sans-serif;margin:0;padding:0;text-align:left;background:linear-gradient(var(--gray-gradient)) no-repeat;background-size:100% 600px;word-wrap:break-word;overflow-wrap:break-word;color:rgb(var(--gray-dark));font-size:20px;line-height:1.7}main{width:720px;max-width:calc(100% - 2em);margin:auto;padding:3em 1em}h1,h2,h3,h4,h5,h6{margin:0 0 .5rem;color:rgb(var(--black));line-height:1.2}h1{font-size:3.052em}h2{font-size:2.441em}h3{font-size:1.953em}h4{font-size:1.563em}h5{font-size:1.25em}strong,b{font-weight:700}a,a:hover{color:var(--accent)}p{margin-bottom:1em}.prose p{margin-bottom:2em}textarea{width:100%;font-size:16px}input{font-size:16px}table{width:100%}img{max-width:100%;height:auto;border-radius:8px}code{padding:2px 5px;background-color:rgb(var(--gray-light));border-radius:2px}pre{padding:1.5em;border-radius:8px}pre>code{all:unset}blockquote{border-left:4px solid var(--accent);padding:0 0 0 20px;margin:0;font-size:1.333em}hr{border:none;border-top:1px solid rgb(var(--gray-light))}@media (max-width: 720px){body{font-size:18px}main{padding:1em}}.sr-only{border:0;padding:0;margin:0;position:absolute!important;height:1px;width:1px;overflow:hidden;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);clip-path:inset(50%);white-space:nowrap}.tag{display:inline-block;background-color:#f3f4f6;border-radius:.5rem;padding:.25rem .75rem;margin:0 .5rem .5rem 0;font-size:.875rem;font-weight:600;color:#4b5563}header[data-astro-cid-3ef6ksr2]{margin:0;padding:0 1em;background:#fff;box-shadow:0 2px 8px rgba(var(--black),5%)}h2[data-astro-cid-3ef6ksr2]{margin:0;font-size:1em}nav[data-astro-cid-3ef6ksr2]{display:flex;align-items:baseline;justify-content:space-between}.internal-links[data-astro-cid-3ef6ksr2]{font-family:SaiyanSans,sans-serif;font-spacing:1em;font-size:2rem}nav[data-astro-cid-3ef6ksr2] .internal-links[data-astro-cid-3ef6ksr2]{margin-right:10em}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{padding:1em .5em;color:var(--black);border-bottom:4px solid transparent;text-decoration:none}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]:hover{color:var(--accent);color:red;animation:shake .2s;animation-iteration-count:1;text-shadow:2px 4px rgba(0,0,0,.2);font-weight:bolder}@keyframes shake{0%{transform:translate(1px,1px) rotate(0)}10%{transform:translate(-1px,-2px) rotate(-5deg)}20%{transform:translate(-3px) rotate(5deg)}30%{transform:translate(3px,2px) rotate(0)}40%{transform:translate(1px,-1px) rotate(5deg)}50%{transform:translate(-1px,2px) rotate(-5deg)}60%{transform:translate(-3px,1px) rotate(0)}70%{transform:translate(3px,1px) rotate(-5deg)}80%{transform:translate(-1px,-1px) rotate(5deg)}90%{transform:translate(1px,2px) rotate(0)}to{transform:translate(1px,-2px) rotate(-5deg)}}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none;border-bottom-color:red}.social-links[data-astro-cid-3ef6ksr2],.social-links[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{display:flex}@media (max-width: 720px){.social-links[data-astro-cid-3ef6ksr2]{display:none}}.aura-container[data-astro-cid-3ef6ksr2]{position:relative;display:inline-block;padding:60px}.aura-text[data-astro-cid-3ef6ksr2]{font-size:2.2rem;font-weight:700;font-family:SaiyanSans,sans-serif;color:red;position:relative;z-index:4;-webkit-text-stroke:1px black;letter-spacing:.1em}.aura-text[data-astro-cid-3ef6ksr2] .yellow[data-astro-cid-3ef6ksr2]{color:#ff0}.aura-text[data-astro-cid-3ef6ksr2] .organge[data-astro-cid-3ef6ksr2]{color:orange}.gif-aura[data-astro-cid-3ef6ksr2]{position:absolute;inset:0;background:url(/CFoa1.gif) center/cover no-repeat;z-index:2;mix-blend-mode:screen;opacity:.8}.gif-bg-1[data-astro-cid-3ef6ksr2],.gif-bg-2[data-astro-cid-3ef6ksr2],.gif-bg-3[data-astro-cid-3ef6ksr2],.gif-bg-4[data-astro-cid-3ef6ksr2],.gif-bg-5[data-astro-cid-3ef6ksr2],.gif-bg-6[data-astro-cid-3ef6ksr2],.gif-bg-7[data-astro-cid-3ef6ksr2],.gif-bg-8[data-astro-cid-3ef6ksr2]{position:absolute;width:150px;height:150px;background:url(/CFoa1.gif) center/contain no-repeat;z-index:4;mix-blend-mode:multiply;opacity:.9}.gif-bg-1[data-astro-cid-3ef6ksr2]{top:-5px;left:-5px;transform:rotate(-20deg)}.gif-bg-2[data-astro-cid-3ef6ksr2]{top:-5px;left:25%;transform:rotate(-5deg)}.gif-bg-3[data-astro-cid-3ef6ksr2]{top:-5px;left:50%;transform:rotate(5deg)}.gif-bg-4[data-astro-cid-3ef6ksr2]{top:-15px;right:-30px;transform:rotate(20deg)}.gif-bg-5[data-astro-cid-3ef6ksr2]{bottom:10px;left:-30px;transform:rotate(-160deg)}.gif-bg-6[data-astro-cid-3ef6ksr2]{bottom:10px;left:25%;transform:rotate(-160deg)}.gif-bg-7[data-astro-cid-3ef6ksr2]{bottom:10px;right:25%;transform:rotate(-160deg)}.gif-bg-8[data-astro-cid-3ef6ksr2]{bottom:10px;right:-30px;transform:rotate(160deg)}footer[data-astro-cid-sz7xmlte]{padding:2em 1em 6em;background:linear-gradient(var(--gray-gradient)) no-repeat;color:rgb(var(--gray));text-align:center}.social-links[data-astro-cid-sz7xmlte]{display:flex;justify-content:center;gap:1em;margin-top:1em}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]{text-decoration:none;color:rgb(var(--gray))}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]:hover{color:rgb(var(--gray-dark))}
a[data-astro-cid-eimmu3lg]{display:inline-block;text-decoration:none}a[data-astro-cid-eimmu3lg].active{font-weight:bolder;text-decoration:underline}
.scrollrectangle[data-astro-cid-bvzihdzo]{position:fixed;right:20px;width:20px;height:100px;background-color:#2c65d7;border-radius:10%;transition:top .3s ease-out;transform-origin:center center;animation:squeeze 1s infinite}@keyframes squeeze{0%{transform:scaleY(1)}50%{transform:scaleY(1.5)}to{transform:scaleY(1)}}main[data-astro-cid-bvzihdzo]{width:calc(100% - 2em);max-width:100%;margin:0}.hero-image[data-astro-cid-bvzihdzo]{width:100%}.hero-image[data-astro-cid-bvzihdzo] img[data-astro-cid-bvzihdzo]{display:block;margin:0 auto;border-radius:12px;box-shadow:var(--box-shadow)}.prose[data-astro-cid-bvzihdzo]{width:720px;max-width:calc(100% - 2em);margin:auto;padding:1em;color:rgb(var(--gray-dark))}.title[data-astro-cid-bvzihdzo]{margin-bottom:1em;padding:1em 0;text-align:center;line-height:1}.title[data-astro-cid-bvzihdzo] h1[data-astro-cid-bvzihdzo]{margin:0 0 .5em}.date[data-astro-cid-bvzihdzo]{margin-bottom:.5em;color:rgb(var(--gray))}.last-updated-on[data-astro-cid-bvzihdzo]{font-style:italic}
</style></head> <body data-astro-cid-bvzihdzo> <header data-astro-cid-3ef6ksr2> <nav data-astro-cid-3ef6ksr2> <div class="aura-container" data-astro-cid-3ef6ksr2> <div class="gif-bg-1" data-astro-cid-3ef6ksr2></div> <div class="gif-bg-2" data-astro-cid-3ef6ksr2></div> <div class="gif-bg-3" data-astro-cid-3ef6ksr2></div> <h2 class="aura-text" data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2> <span class="yellow" data-astro-cid-3ef6ksr2>Govind's</span> <span class="orange" data-astro-cid-3ef6ksr2>O</span> <span data-astro-cid-3ef6ksr2>Blog</span> </a></h2> </div> <div class="internal-links" data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Home </a>  <a href="/blog" class="active" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Blog </a>  <a href="/ideas" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Steal My Ideas </a>  <a href="/editor" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Image Editor </a>  </div> <div class="social-links" data-astro-cid-3ef6ksr2> <a href="https://x.com/DeepknowledgeU" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Follow Astro on X</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/twitter" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z" data-astro-cid-3ef6ksr2></path></svg> </a> <a href="https://github.com/Gowind" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>My Github</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/github" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-3ef6ksr2></path></svg> </a> </div> </nav> </header>  <main data-astro-cid-bvzihdzo> <article data-astro-cid-bvzihdzo> <div class="scrollrectangle" data-astro-cid-bvzihdzo></div> <script type="module">const o=document.querySelector(".ball"),c=document.querySelector("header"),r=document.documentElement.scrollHeight-window.innerHeight,t=c?.offsetHeight;o.style.top=`${t+100}px`;window.addEventListener("scroll",()=>{const n=window.scrollY/r,l=window.innerHeight-100;let e=n*l;e=e>=t+100?e:t+100,o.style.top=`${e}px`});</script> <div class="hero-image" data-astro-cid-bvzihdzo> <img width="1020" height="510" src="/blog-placeholder-5.jpg" alt="" data-astro-cid-bvzihdzo> </div> <div class="prose" data-astro-cid-bvzihdzo> <div class="title" data-astro-cid-bvzihdzo> <div class="date" data-astro-cid-bvzihdzo> <time datetime="2024-10-24T00:00:00.000Z"> Oct 24, 2024 </time>  </div> <h1 data-astro-cid-bvzihdzo>SIMD algos part II: popcount</h1> <hr data-astro-cid-bvzihdzo> </div>  <h1 id="hamming-weight-or-popcount">Hamming Weight or Popcount</h1>
<p>A very popular task in Computing is counting the number of ones in a byte or a set of bites.
This task is called <a href="https://en.wikipedia.org/wiki/Hamming_weight">Hamming Weight</a> or population count or more simply, popcount. Popcount is a popular enough instruction that most CPUs provide hardware instructions instead of relying on software routines. x86-64 provides a <code>popcnt</code> instruction that calculate the number of set bits in the source operand 64-bit register. ARM has a <code>CNT</code> instruction that calculates the number of set bits in the source 128-bit SIMD register.</p>
<p>You can access the popcount instruction using the <code>__builtin_popcount</code> fn in GCC (or Clang). GCC supports <a href="https://gcc.gnu.org/onlinedocs/gcc/Other-Builtins.html">builtin functions</a> , functions that extend features in C or provide optimized implementations of fns in the C standard library. The builtin might or might not use a hardware provided instruction to implement <code>popcount</code></p>
<p>The <a href="https://github.com/CountOnes/hamming_weight">Hamming Weight Repository</a> has a number of different implementations of popcount for both 32/64-bit values and SIMD accelerated versions to calculate the number of set bits in an array of 64-bit unsigned integers, each integer holding 64 counts (1/0).
I ran the benchmarks on a Core i5-10210U processor and , While the fastest implementation is  <code>avx2_harley_seal_bitset64_weight_unrolled_twice</code>, I modified the <code>avx2_bitset64_weight</code>implementation so that is easier to understand while still faster than the scalar popcount version that calculates popcount for an array of values in a loop, something like</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>for(int i=0;i&#x3C;N;i++) {</span></span>
<span class="line"><span>  totalCount += popcount(a[i]);</span></span>
<span class="line"><span>}</span></span></code></pre>
<p>My implementation is a bit interesting. I assumed that eliminating the inner loop from the <code>avx2_bitset64_weight</code> would make my implementation faster, but surprise ! It actually ended up running ~20% slower THAN the one with an inner loop ! How come ? Did the inner loop get unrolled ? Or is the additional instruction that I used so much slower that the overhead of a second loop was lower than it ? I don’t know yet, perhaps someday I will get good enough with perf observations and microarchitectures to make a hypothesis and prove it. But for now, we can continue using my implementation to understand SIMD instructions while still not being slow.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>size = 12288 words or 98304 bytes </span></span>
<span class="line"><span>lauradoux_bitset64_weight(prec, size)                       	:  1.89 cycles per operation (best) 	1.95 cycles per operation (avg) </span></span>
<span class="line"><span>scalar_bitset64_weight(prec, size)                          	:  2.67 cycles per operation (best) 	2.77 cycles per operation (avg) </span></span>
<span class="line"><span>scalar_harley_seal8_bitset64_weight(prec, size)             	:  1.43 cycles per operation (best) 	1.47 cycles per operation (avg) </span></span>
<span class="line"><span>scalar_harley_seal_bitset64_weight(prec, size)              	:  1.31 cycles per operation (best) 	1.32 cycles per operation (avg) </span></span>
<span class="line"><span>table_bitset8_weight((uint8_t *)prec, size * 8)             	:  4.75 cycles per operation (best) 	4.76 cycles per operation (avg) </span></span>
<span class="line"><span>table_bitset16_weight((uint16_t *)prec, size * 4)           	:  3.14 cycles per operation (best) 	3.21 cycles per operation (avg) </span></span>
<span class="line"><span>....</span></span>
<span class="line"><span>sse_harley_seal_bitset64_weight(prec, size)                 	:  0.64 cycles per operation (best) 	0.64 cycles per operation (avg) </span></span>
<span class="line"><span>avx2_bitset64_weight(prec, size)                            	:  0.38 cycles per operation (best) 	0.39 cycles per operation (avg) </span></span>
<span class="line"><span>gov_avx2_bitset64_weight(prec, size)                        	:  0.48 cycles per operation (best) 	0.48 cycles per operation (avg) </span></span>
<span class="line"><span>avx2_lookup_bitset64_weight(prec, size)                     	:  0.38 cycles per operation (best) 	0.39 cycles per operation (avg) </span></span>
<span class="line"><span>avx2_lookup2_bitset64_weight(prec, size)                    	:  0.39 cycles per operation (best) 	0.40 cycles per operation (avg) </span></span>
<span class="line"><span>avx2_lauradoux_bitset64_weight(prec, size)                  	:  0.48 cycles per operation (best) 	0.50 cycles per operation (avg) </span></span>
<span class="line"><span>.....</span></span>
<span class="line"><span>avx2_harley_seal_nate_bitset64_weight(prec, size)           	:  0.32 cycles per operation (best) 	0.33 cycles per operation (avg) </span></span>
<span class="line"><span>avx2_harley_seal_walisch_bitset64_weight(prec, size)        	:  0.34 cycles per operation (best) 	0.35 cycles per operation (avg) </span></span>
<span class="line"><span>avx2_harley_seal_bitset64_weight_unrolled_twice(prec, size) 	:  0.30 cycles per operation (best) 	0.31 cycles per operation (avg) </span></span>
<span class="line"><span>no AVX512 instructions</span></span>
<span class="line"><span>no XOP instructions</span></span>
<span class="line"><span></span></span>
<span class="line"><span>Output of running the benchmarks with my implementation. While having no nested loop like avx2_bitset64_weight, it still ended up being roughly 20-25% slower per cycle than the avx2_bitset64_weight fn</span></span></code></pre>
<p>The <a href="https://github.com/CountOnes/hamming_weight/blob/master/src/avx_hamming_weight.c">implementation</a> is the following snippet (<strong>NOTE</strong>: the snippet below is a modified version of the one in the repository)</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>// compute the Hamming weight of an array of 64-bit words using AVX2 instructions</span></span>
<span class="line"><span>int gov_avx2_bitset64_weight(const uint64_t * array, size_t length) {</span></span>
<span class="line"><span>    if(length &#x3C; 4) {</span></span>
<span class="line"><span>      int leftover = 0;</span></span>
<span class="line"><span>      for(size_t k = 0; k &#x3C; length; ++k) {</span></span>
<span class="line"><span>        leftover += _mm_popcnt_u64(array[k]);</span></span>
<span class="line"><span>      }</span></span>
<span class="line"><span>      return leftover;</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>    uint64_t* next = array;</span></span>
<span class="line"><span>    int outer = length / 4;</span></span>
<span class="line"><span>    // these are precomputed hamming weights (weight(0), weight(1)...)</span></span>
<span class="line"><span>    const __m256i shuf =</span></span>
<span class="line"><span>        _mm256_setr_epi8(0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4, 0, 1,</span></span>
<span class="line"><span>                         1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4);</span></span>
<span class="line"><span>    const __m256i mask = _mm256_set1_epi8(0x0f);  // low 4 bits of each byte</span></span>
<span class="line"><span>    __m256i zero = _mm256_setzero_si256();</span></span>
<span class="line"><span>    __m256i total = _mm256_setzero_si256();</span></span>
<span class="line"><span>    for (int k = 0; k &#x3C; outer; k++) {</span></span>
<span class="line"><span>        next = array + (k * 4);</span></span>
<span class="line"><span>        __m256i innertotal = _mm256_setzero_si256();</span></span>
<span class="line"><span>        __m256i ymm1 =</span></span>
<span class="line"><span>          _mm256_lddqu_si256((const __m256i *)next);</span></span>
<span class="line"><span>        __m256i ymm2 =</span></span>
<span class="line"><span>          _mm256_srli_epi32(ymm1, 4);  // shift right, shiftingin zeroes</span></span>
<span class="line"><span>        ymm1 = _mm256_and_si256(ymm1, mask);  // contains even 4 bits</span></span>
<span class="line"><span>        ymm2 = _mm256_and_si256(ymm2, mask);  // contains odd 4 bits</span></span>
<span class="line"><span>        ymm1 = _mm256_shuffle_epi8(</span></span>
<span class="line"><span>            shuf, ymm1);  // use table look-up to sum the 4 bits</span></span>
<span class="line"><span>        ymm2 = _mm256_shuffle_epi8(shuf, ymm2);</span></span>
<span class="line"><span>        innertotal = _mm256_add_epi8(innertotal, ymm1);  // inner total</span></span>
<span class="line"><span>        innertotal = _mm256_add_epi8(innertotal, ymm2);  // inner total</span></span>
<span class="line"><span>        innertotal = _mm256_sad_epu8(zero, innertotal);  // produces 4 64-bit</span></span>
<span class="line"><span>        total = _mm256_add_epi64(total, innertotal);</span></span>
<span class="line"><span></span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>    const int leftoverwords =  length % 4;</span></span>
<span class="line"><span>    int leftover = 0;</span></span>
<span class="line"><span>    for(size_t k = length - leftoverwords; k &#x3C; length; ++k) {</span></span>
<span class="line"><span>      leftover += _mm_popcnt_u64(array[k]);</span></span>
<span class="line"><span>    }</span></span>
<span class="line"><span>    return leftover + _mm256_extract_epi64(total, 0) +    _mm256_extract_epi64(total, 1) +</span></span>
<span class="line"><span>           _mm256_extract_epi64(total, 2) + _mm256_extract_epi64(total, 3);</span></span>
<span class="line"><span>}</span></span></code></pre>
<p>The leftover portion deals with 2 cases:</p>
<ol>
<li>When the total number of bits in the array is &#x3C; 256. In that case, just use the scalary version</li>
<li>When the array size is not a multiple of 8 64-bit ints. In this case, the last  N % 8 bits are processed serially.</li>
</ol>
<p>The remaining N / 8 bytes are handled in a SIMD accelerated loop. I shall try to illustrate the algorithm using a real example for an array of inputs</p>
<p>as input, lets use</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>  uint64_t a[61] = {[0 ... 60] = 0xFEAA0088};</span></span></code></pre>
<p>There are 13 set bits in <code>0xFEAA0088</code>. An array of 61 values must therefore yield us 13 * 61 = 793.</p>
<p>I do not want to focus on the entire body of the fn, but only on the loop <code>for (int k = 0; k &#x3C; outer; k++) {</code>. The rest as mentioned is just dealing with the leftovers array_size % 32 bytes serially.</p>
<p>The value <code>shuf</code> is quite clever. It stores a pre-computed array of values, where the index is a number between 0-15 (that is 0x0 - 0xF) and the value is the number of bits in the index (shuf[16 / 0xF] = 3). Thus, in each iteration, we can split our input 256 bits into 64, 4-bit values and simply loop over the count of <code>1</code>s in each of the 4-bit values to get the final tally of <code>1</code>s ! Quite clever eh ?
There is one more very clever optimization: Normally arrays are stored in the memory as a continuous set of bytes : <code>a[0], a[1], a[2]</code>. When fetching a memory location <code>a[n]</code>, if the value is not in the CPU’s cache, it must be fetched from the main memory, thus stalling the instruction and slowing performance. However, shuf is <strong>NOT</strong> an array, but a single 256-bit register value. This means that to do a lookup of <code>1s</code> in a 4 bit value, no Cache/Memory lookup is needed as the entire array fits into a single register and we can lookup the hamming weight of a 4-bit value using just a shuffle SIMD instruction !</p>
<p>To calculate the number of <code>1</code>s , we split our input 256 bits into 4-bits each  first and this is how we do it:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>   __m256i ymm1 =</span></span>
<span class="line"><span>          _mm256_lddqu_si256((const __m256i *)next);</span></span>
<span class="line"><span>        __m256i ymm2 =</span></span>
<span class="line"><span>          _mm256_srli_epi32(ymm1, 4);  // shift right, shiftingin zeroes</span></span>
<span class="line"><span>        ymm1 = _mm256_and_si256(ymm1, mask);  // contains even 4 bits</span></span>
<span class="line"><span>        ymm2 = _mm256_and_si256(ymm2, mask);  // contains odd 4 bits</span></span>
<span class="line"><span>     </span></span></code></pre>
<p><code>ymm1</code> has the 256 bits under consideration. We then load <code>ymm2</code>  with <code>ymm1</code>, butwhere each 32-bit lane is right shifted by 0 4 times.
Given our example array above, <code>ymmm1</code> would look something like</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>[0xFEAA0088 00000000 0xFEAA0088 00000000 0xFEAA0088 00000000 0xFEAA0088 00000000]</span></span></code></pre>
<p>(Intel is little-endian so a 64-bit integer representing <code>0xFEAA0088</code> is <code>0x00000000FEAA0088</code> and the Least Significant Bytes are stored in the first memory address followed by the second and so on)
Shifted right by 4 bits in each 32-bit lane, we get ymm2</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>[0x0FEAA008 00000000 0x0FEAA008 00000000 0x0FEAA008 00000000 0x0FEAA008 00000000]</span></span></code></pre>
<p>If I <code>and</code> both <code>ymm1</code> and <code>ymm2</code> with a mask register of repeated <code>0x0F</code> values</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>[0x0FEAA008 00000000 0x0FEAA008 00000000 0x0FEAA008 00000000 0x0FEAA008 00000000]</span></span>
<span class="line"><span>&#x26;&#x26;</span></span>
<span class="line"><span>[0x0F0F0F0F 0x0F0F0F0F 0x0F0F0F0F 0x0F0F0F0F 0x0F0F0F0F 0x0F0F0F0F 0x0F0F0F0F 0x0F0F0F0F]</span></span></code></pre>
<p>essentially I endup with 2 all the even 4-bits in ymm1 and the odd 4-bits in ymm2.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>[0x0F0A0008 00000000 0x0F0A0008 0x00000000 0x0F0A0008 0x00000000 0x0F0A0008 0x00000000]</span></span></code></pre>
<p>In both <code>ymm1</code> and <code>ymm2</code> we only select 4-bits out of each 8-bit lane from the input. This means that the higher 4-bits of each 8-bit lane is 0, thus each 8-bit lane has a value [0..15]. Using the <code>shuffle</code> intrinsic, we can lookup number of <code>1</code>s in each 8-bit lane from <code>shuf</code> register</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>ymm2 = _mm256_shuffle_epi8(shuf, ymm2)</span></span>
<span class="line"><span>// this is akin to doing</span></span>
<span class="line"><span>for(int i = 0; i &#x3C; 32;i++) {</span></span>
<span class="line"><span> ymm2[i] = shuf[ymm2[i]];</span></span>
<span class="line"><span>}</span></span></code></pre>
<p>We do not have to worry about overflowing because all the values in shuf are &#x3C; 16
After the <code>shuffle</code> intrinsice, <code>ymm1</code> will contain the number of <code>1</code>s in the even 4-bits and <code>ymm2</code> will contain the number of <code>1</code>s in the odd 4-bits. We then add them lane-wise to a running counter <code>innertotal</code></p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>innertotal = _mm256_add_epi8(innertotal, ymm1);  // inner total</span></span>
<span class="line"><span>innertotal = _mm256_add_epi8(innertotal, ymm2);  // inner total</span></span></code></pre>
<p>We do not have to worry about overflows here as well, as the max value in each 8-bit lane is 32 (16 + 16).</p>
<p>Our final count will be the sum of all of the 8-bit lanes in <code>innertotal</code>.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>total = 0;</span></span>
<span class="line"><span>for(int i=0;i&#x3C;32;i++) { total += register[lane_i];}</span></span></code></pre>
<p>Unfortunately, there is no intrinsic in avx2 to do this operation, so we employ a little trick using the <code>_mm256_sad_epu8</code> or the Sum Absolute Differences intrinsic</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>innertotal = _mm256_sad_epu8(zero, innertotal);  // produces 4 64-bit</span></span>
<span class="line"><span>total = _mm256_add_epi64(total, innertotal);</span></span></code></pre>
<p>the <code>sad_epu8</code> intrinsic, subtracts each 8-bit lane from register b (innertotal) from register a (zero), takes the absolute of the value and adds them with the value from the other lanes.</p>
<p>it emits 4 64-bit values containing the sum of 8, 8-bit lanes. To make this easier to understand here is the output of the previous 2 intrinsics</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>innertotal: [0x07040002, 0x00000000, 0x07040002, 0x00000000, 0x07040002, 0x00000000, 0x07040002, 0x00000000, ]</span></span>
<span class="line"><span>total: [0x0000000D, 0x00000000, 0x0000000D, 0x00000000, 0x0000000D, 0x00000000, 0x0000000D, 0x00000000, ]</span></span></code></pre>
<p>The first 64-bit lane in <code>total</code> contains the value 0xD (or decimal 13), which is the sum of the first 8 8 bit lanes in <code>innertotal</code>. This incidentally is also number of <code>1</code>s in each of the elements in the input array !</p>
<p>Once the loops are processed, we process any leftover values</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>const int leftoverwords =  length % 4;</span></span>
<span class="line"><span>int leftover = 0;</span></span>
<span class="line"><span>for(size_t k = length - leftoverwords; k &#x3C; length; ++k) {</span></span>
<span class="line"><span>      leftover += _mm_popcnt_u64(array[k]);</span></span>
<span class="line"><span>}</span></span></code></pre>
<p>Since our total is a vector register and we are returning a single 64-bit value, we must extract each 64-bit value from our <code>total</code> register. We can do that using <code>__mm256_extract_epi64(register, lane)</code> to extract the 64-bit value in <code>lane</code>.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>return leftover + _mm256_extract_epi64(total, 0) + _mm256_extract_epi64(total, 1) </span></span>
<span class="line"><span>+ _mm256_extract_epi64(total, 2) + _mm256_extract_epi64(total, 3);</span></span></code></pre>
<p>Using SIMD , we thus process 256-bits in a go instead of 64-bits in each iteration using <code>      _mm_popcnt_u64(array[k])</code>, with potentially upto 4x the speed up (in reality, due to loop overhead and multiple instructions per loop iteration, the speed is 2x or less)</p>
<h3 id="conclusion">Conclusion</h3>
<p>We used SIMD to solve a problem with real world applications and not just as a contrived example. I was very surprised by the fact that my fn with no inner loop ended up being slower than one with 2 loops. Clearly O(n^2) must be slower than O(n) right ?
I still have no idea how this happened , but I speculate that with all the optimization flags turned on, the compiler decided to unroll the innerloop thus avoiding the overhead of the loop, or am I getting slowed down due to microarchitecture issues ? I will continue investigating this and hopefully in the future have an answer.</p>  </div> </article> </main> <footer data-astro-cid-sz7xmlte> <div class="social-links" data-astro-cid-sz7xmlte> <a href="https://x.com/DeepknowledgeU" target="_blank" data-astro-cid-sz7xmlte> <span class="sr-only" data-astro-cid-sz7xmlte>Follow Astro on X</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/twitter" data-astro-cid-sz7xmlte><path fill="currentColor" d="M5.026 15c6.038 0 9.341-5.003 9.341-9.334 0-.14 0-.282-.006-.422A6.685 6.685 0 0 0 16 3.542a6.658 6.658 0 0 1-1.889.518 3.301 3.301 0 0 0 1.447-1.817 6.533 6.533 0 0 1-2.087.793A3.286 3.286 0 0 0 7.875 6.03a9.325 9.325 0 0 1-6.767-3.429 3.289 3.289 0 0 0 1.018 4.382A3.323 3.323 0 0 1 .64 6.575v.045a3.288 3.288 0 0 0 2.632 3.218 3.203 3.203 0 0 1-.865.115 3.23 3.23 0 0 1-.614-.057 3.283 3.283 0 0 0 3.067 2.277A6.588 6.588 0 0 1 .78 13.58a6.32 6.32 0 0 1-.78-.045A9.344 9.344 0 0 0 5.026 15z" data-astro-cid-sz7xmlte></path></svg> </a> <a href="https://github.com/Gowind" target="_blank" data-astro-cid-sz7xmlte> <span class="sr-only" data-astro-cid-sz7xmlte>My Github</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" astro-icon="social/github" data-astro-cid-sz7xmlte><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-sz7xmlte></path></svg> </a> </div> </footer>  </body></html>